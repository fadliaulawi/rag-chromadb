{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi menggunakan format BioASQ dari hasil RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampai saat ini, mungkin temen2 udah coba buat code RAG yang bisa dipakai sampai model RAGnya bisa **men-generate jawaban** dari suatu pertanyaan. Nah untuk evaluasi ini, ternyata aku butuh code RAG temen2 hanya sampai **menghasilkan dokumen-dokumen yang terkait** saja. Karena kita ingin menyamakan tujuan eksperimen di papernya yaitu menggunakan **model BioBERT** untuk menjawab pertanyaan tsb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 0. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\nico\\internship\\kalbe\\PRICAI\\rag-chromadb\\env\\lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "c:\\nico\\internship\\kalbe\\PRICAI\\rag-chromadb\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone\n",
    "from query_expansion import single_query_expansion, multiple_query_expansion\n",
    "\n",
    "character_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"], chunk_size=250, chunk_overlap=50)\n",
    "token_splitter = SentenceTransformersTokenTextSplitter(tokens_per_chunk=250, chunk_overlap=50)\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def embedding_function(text, model=\"text-embedding-ada-002\"):\n",
    "\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=model\n",
    "    )\n",
    "\n",
    "    embedding = response.data[0].embedding\n",
    "    return embedding\n",
    " \n",
    "pc = Pinecone(api_key=os.environ['PINECONE_API_KEY'])\n",
    "index = pc.Index(\"rag-kak\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Looping pertanyaan untuk dicari dokumen-dokumen terkaitnya\n",
    "\n",
    "Di repo ini sudah aku siapkan data pertanyaan di *data/test_data/BioASQ-test-yesno-rag-11b.json*. Codenya sudah aku siapkan, dan aku minta temen2 untuk menghubungkan code ini dengan **metode RAG masing2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/test_data/BioASQ-test-yesno-rag-11b.json')\n",
    "\n",
    "output_json = {\n",
    "    'data': [\n",
    "        {\n",
    "            'paragraphs': [],\n",
    "            'title': 'BioASQ11b'\n",
    "        }\n",
    "    ],\n",
    "    'version': 'BioASQ11b'\n",
    "}\n",
    "\n",
    "for i in df.index:\n",
    "    query = df.loc[i, 'questions']\n",
    "    id = df.loc[i, 'ids']\n",
    "\n",
    "    # TODO: Function ini yang dihubungkan ke code RAG temen2\n",
    "    # Expected dari retrieved_documents isinya list of vectors dari index 'rag-kak' di Pinecone, yang paling relevan dengan query.\n",
    "    # Ex: [\"aaa\", \"bbb\", ] (ambil top 10 docs)\n",
    "    retrieved_documents = multiple_query_expansion(query)\n",
    "    context = '\\n'.join(retrieved_documents)\n",
    "\n",
    "    dct = {\n",
    "        'qas': [\n",
    "            {\n",
    "                'id': f\"{id}_001\",\n",
    "                'question': query\n",
    "            }\n",
    "        ],\n",
    "        'context': context\n",
    "    }\n",
    "    output_json['data'][0]['paragraphs'].append(dct)\n",
    "\n",
    "with open('data/test_data/BioASQ-test-yesno-11b.json', 'w') as outfile: \n",
    "    json.dump(output_json, outfile, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil dari code tersebut adalah list of pertanyaan with contextnya yang disimpan di *data/test_data/BioASQ-test-yesno-11b.json*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Evaluasi menggunakan standard dataset BioASQ dan model BioBERT\n",
    "\n",
    "Disini kita akan pakai code dari pihak BioASQ untuk melakukan evaluasi sekaligus mengeluarkan metriksnya. Step2 detailnya sebagai berikut: \n",
    "\n",
    "Note: (disaranin banget jalanin di colab/kaggle karena butuh GPU dan Java)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a. Pertama temen2 bisa clone, dan masuk ke direktorinya:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/dmis-lab/biobert-pytorch\n",
    "cd biobert-pytorch/question-answering/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b. Ubah sedikit bagian code di run_yesno.py:\n",
    "Pada line 579 saat load Tokenizer, tambahkan\n",
    "```bash\n",
    "use_fast=False\n",
    "```\n",
    "pada parameternya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2c. Pindahkan data train dan test (question dan answer) ke direktori ini\n",
    "Copy dua data dari repo sebelumnya (rag-chromadb) ke dalam repo folder ini (biobert-pytorch/question-answering). Data yang dipindahkan adalah \n",
    "\n",
    "- *data/train_data/BioASQ-train-yesno-11b.json* \n",
    "- *data/test_data/BioASQ-test-yesno-11b.json* \n",
    "- *data/test_data/11B_golden.json*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2d. Jalankan command berikut untuk melakukan training dan testing:\n",
    "\n",
    "```bash\n",
    "!python run_yesno.py \\\n",
    "    --model_type bert \\\n",
    "    --model_name_or_path \"dmis-lab/biobert-base-cased-v1.1-squad\" \\\n",
    "    --do_train \\\n",
    "    --train_file \"BioASQ-train-yesno-11b.json\" \\\n",
    "    --per_gpu_train_batch_size 12 \\\n",
    "    --learning_rate 8e-6 \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --max_seq_length 384 \\\n",
    "    --seed 0 \\\n",
    "    --output_dir \"output/\"\n",
    "```\n",
    "\n",
    "```bash\n",
    "python run_yesno.py \\\n",
    "    --model_type bert \\\n",
    "    --model_name_or_path \"dmis-lab/biobert-base-cased-v1.1-squad\" \\\n",
    "    --do_eval \\\n",
    "    --predict_file \"BioASQ-test-yesno-11b.json\" \\\n",
    "    --golden_file \"11B_golden.json\" \\\n",
    "    --output_dir \"output/\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2e. Keluar hasilnya:\n",
    "\n",
    "Jika berjalan lancar, contoh keluaran hasilnya akan seperti ini:\n",
    "\n",
    "![Embedding Adaptors](assets/eval.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selesai. Bisa dicatat nilai-nilainya"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
